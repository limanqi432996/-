#!/usr/bin/env python
# coding: utf-8

# In[ ]:


# import numpy as np
# import pandas as pd
# import os
# from scipy import stats
# import matplotlib.pyplot as plt
# import seaborn as sns
# from pylab import rcParams
# import matplotlib.cm as cm

# import sklearn 
# from sklearn import preprocessing
# from sklearn.preprocessing import LabelEncoder
# from sklearn.preprocessing import StandardScaler
# from sklearn.model_selection import StratifiedShuffleSplit

# from sklearn.ensemble import RandomForestClassifier
# from sklearn.svm import SVC,LinearSVC
# from sklearn.linear_model import LogisticRegression
# from sklearn.neighbors import KNeighborsClassifier
# from sklearn.naive_bayes import GaussianNB
# from sklearn.tree import DecisionTreeClassifier

# import xgboost as xgb
# from xgboost import XGBClassifier
# from catboost import CatBoostClassifier
# from sklearn.ensemble import AdaBoostClassifier
# from sklearn.ensemble import GradientBoostingClassifier

# from sklearn.metrics import classification_report,precision_score,recall_score,f1_score
# from sklearn.metrics import confusion_matrix
# from sklearn.model_selection import GridSearchCV
# from sklearn.metrics import make_scorer
# from sklearn.ensemble import VotingClassifier

# from sklearn.decomposition import PCA
# from sklearn.cluster import KMeans
# from sklearn.metrics import silhouette_score

# import warnings
# warnings.filterwarnings("ignore")

# sns.set(style='darkgrid',font_scale=1.3)
# plt.rcParams['font.sans-serif'] = ['SimHei']  # ç¡®ä¿ä¸­æ–‡æ˜¾ç¤ºæ­£å¸¸
# plt.rcParams['axes.unicode_minus'] = False   # ç¡®ä¿è´Ÿå·æ˜¾ç¤ºæ­£å¸¸

# %matplotlib inline



# telcom = pd.read_csv('Customer-Churn.csv')
# print(telcom.head())

# #æŸ¥æ‰¾ç¼ºå¤±å€¼
# pd.isnull(telcom).sum()

# #æŸ¥çœ‹æ•°æ®ç±»å‹
# telcom.info()

# # totalchargesæ€»è´¹ç”¨ï¼Œéœ€è¦è½¬æ¢ä¸ºfloatç±»å‹
# telcom['TotalCharges'] = pd.to_numeric(telcom['TotalCharges'], errors='coerce')
# telcom['TotalCharges'].dtypes

# # æŸ¥çœ‹ç¼ºå¤±å€¼
# pd.isnull(telcom["TotalCharges"]).sum() 

# # ä¸­ä½æ•°å¡«å……
# telcom.fillna({'TotalCharges':telcom['TotalCharges'].median()},inplace=True)

# #æ•°æ®å½’ä¸€åŒ–

# #å¯¹Churnä¸€åˆ—çš„å€¼ç”¨1 0 ä»£æ›¿ï¼Œæ–¹ä¾¿å¤„ç†
# telcom['Churn'].replace(to_replace = "Yes",value=1,inplace=True)
# telcom['Churn'].replace(to_replace = "No",value=0,inplace=True)
# telcom['Churn'].head()

# #1ã€æå–ç‰¹å¾
# churn_var=telcom.iloc[:,2:20]
# churn_var.drop("PhoneService",axis=1, inplace=True)
# churn_var.head()

# #2ã€å¤„ç†é‡çº²å·®å¼‚å¤§
# # â€œMonthlyCharges"ã€"TotalCharges"ä¸¤ä¸ªç‰¹å¾è·Ÿå…¶ä»–ç‰¹å¾ç›¸æ¯”ï¼Œé‡çº²å·®å¼‚å¤§
# #ç‰¹å¾ç¦»æ•£åŒ– æ¨¡å‹æ˜“äºå¿«é€Ÿè¿­ä»£ï¼Œä¸”æ¨¡å‹æ›´ç¨³å®š
# #æŸ¥çœ‹'MonthlyCharges'åˆ—çš„4åˆ†ä½
# churn_var['MonthlyCharges'].describe() 

# #ç”¨å››åˆ†ä½æ•°è¿›è¡Œç¦»æ•£
# churn_var['MonthlyCharges']=pd.qcut(churn_var['MonthlyCharges'],4,labels=['1','2','3','4'])
# churn_var['MonthlyCharges'].head()

# #æŸ¥çœ‹'TotalCharges'åˆ—çš„4åˆ†ä½
# churn_var['TotalCharges'].describe()

# #ç”¨å››åˆ†ä½æ•°è¿›è¡Œç¦»æ•£ 
# churn_var['TotalCharges']=pd.qcut(churn_var['TotalCharges'],4,labels=['1','2','3','4'])
# churn_var['TotalCharges'].head()

# # 3ã€åˆ†ç±»æ•°æ®è½¬æ¢æˆâ€œæ•´æ•°ç¼–ç â€
# # æŸ¥çœ‹churn_varä¸­åˆ†ç±»å˜é‡çš„labelæ ‡ç­¾

# #è‡ªå®šä¹‰å‡½æ•°è·å–åˆ†ç±»å˜é‡ä¸­çš„label
# def Label(x):
#     print(x,"--" ,churn_var[x].unique()) 
# #ç­›é€‰å‡ºæ•°æ®ç±»å‹ä¸ºâ€œobjectâ€çš„æ•°æ®ç‚¹
# df_object=churn_var.select_dtypes(['object']) 
# print(list(map(Label,df_object)))

# #é€šè¿‡åŒè¡Œç™¾åˆ†æ¯”çš„â€œäº¤å‰åˆ†æâ€å‘ç°ï¼Œlabel â€œNo internetseriveâ€çš„äººæ•°å æ¯”åœ¨ä»¥ä¸‹ç‰¹å¾
# # [OnlineSecurityï¼ŒOnlineBackupï¼ŒDeviceProtectionï¼ŒTechSupportï¼ŒStreamingTVï¼ŒStreamingTV]éƒ½æ˜¯æƒŠäººçš„ä¸€è‡´ï¼Œ
# # æ•…æˆ‘ä»¬å¯ä»¥åˆ¤æ–­label â€œNo internetseriveâ€ä¸å½±å“æµå¤±ç‡ã€‚
# # å› ä¸ºè¿™6é¡¹å¢å€¼æœåŠ¡ï¼Œéƒ½æ˜¯éœ€è¦å¼€é€šâ€œäº’è”ç½‘æœåŠ¡â€çš„åŸºç¡€ä¸Šæ‰äº«å—å¾—åˆ°çš„ã€‚ä¸å¼€é€šâ€œäº’è”ç½‘æœåŠ¡â€è§†ä¸ºæ²¡å¼€é€šè¿™6é¡¹å¢å€¼æœåŠ¡ï¼Œ
# # æ•…å¯ä»¥å°† 6ä¸ªç‰¹æ­£ä¸­çš„â€œNo internetseriveâ€ å¹¶åˆ° â€œNoâ€é‡Œé¢ã€‚


# churn_var.replace(to_replace='No internet service',value='No',inplace=True)

# churn_var.replace(to_replace='No phone service',value='No',inplace=True)
# df_object=churn_var.select_dtypes(['object']) 
# print(list(map(Label,df_object.columns)))

# # æ•´æ•°ç¼–ç  sklearnä¸­çš„LabelEncoder()
# def labelencode(x):
#     churn_var[x] = LabelEncoder().fit_transform(churn_var[x])
# for i in range(0,len(df_object.columns)):
#     labelencode(df_object.columns[i])
# print(list(map(Label,df_object.columns)))

# # 4ã€å¤„ç†â€œæ ·æœ¬ä¸å‡è¡¡â€
# #åˆ†æ‹†å˜é‡
# x=churn_var
# y=telcom['Churn'].values
# print('æŠ½æ ·å‰çš„æ•°æ®ç‰¹å¾',x.shape)
# print('æŠ½æ ·å‰çš„æ•°æ®æ ‡ç­¾',y.shape)


# # æ£€æŸ¥ç‰¹å¾åˆ—æ•°æ®ç±»å‹
# print(x.dtypes)

# # æ£€æŸ¥ç›®æ ‡åˆ—ç±»å‹
# print(y.dtype)

# # ç¡®ä¿æ‰€æœ‰ç‰¹å¾ä¸ºæ•°å€¼å‹
# x = x.apply(pd.to_numeric, errors='coerce')  # å­—ç¬¦ä¸²è‡ªåŠ¨è½¬NaN
# x = x.dropna(axis=1)  # åˆ é™¤æ— æ³•è½¬æ¢çš„åˆ—

# # ç¡®ä¿ç›®æ ‡å˜é‡ä¸ºæ•´æ•°å‹
# y = y.astype(int)

# from imblearn.over_sampling import SMOTE
# model_smote = SMOTE(random_state=42)  # å¿…é¡»æ·»åŠ random_state
# x_resampled, y_resampled = model_smote.fit_resample(x, y)  # æ”¹ç”¨fit_resample()

# # è½¬æ¢å›DataFrameï¼ˆå®‰å…¨å†™æ³•ï¼‰
# x_resampled = pd.DataFrame(x_resampled, columns=[col for col in churn_var.columns if col != 'Churn'])

# # åˆ†æ‹†æ•°æ®é›†ï¼ˆæ–°ç‰ˆæ¨èå‚æ•°ï¼‰
# from sklearn.model_selection import train_test_split
# x_train, x_test, y_train, y_test = train_test_split(
#     x_resampled, 
#     y_resampled,
#     test_size=0.3,
#     random_state=42,  # é¿å…ä½¿ç”¨0
#     stratify=y_resampled  # æ–°å¢åˆ†å±‚æŠ½æ ·
# )
# print('è¿‡æŠ½æ ·æ•°æ®ç‰¹å¾ï¼š', x.shape,
#       'è®­ç»ƒæ•°æ®ç‰¹å¾ï¼š',x_train.shape,
#       'æµ‹è¯•æ•°æ®ç‰¹å¾ï¼š',x_test.shape)

# print('è¿‡æŠ½æ ·åæ•°æ®æ ‡ç­¾ï¼š', y.shape,
#       '   è®­ç»ƒæ•°æ®æ ‡ç­¾ï¼š',y_train.shape,
#       '   æµ‹è¯•æ•°æ®æ ‡ç­¾ï¼š',y_test.shape)

# # XGBç®—æ³•
# model_xgb= XGBClassifier()
# model_xgb.fit(x_train,y_train)
# from xgboost import plot_importance
# plot_importance(model_xgb,height=0.5)


# import joblib
# # ä¿å­˜è®­ç»ƒå¥½çš„XGBoostæ¨¡å‹
# joblib.dump(model_xgb, 'xgb_model.pkl')

# # ä¿å­˜ç‰¹å¾åˆ—åï¼ˆç”¨äºStreamlitè¾“å…¥åŒ¹é…ï¼‰
# feature_names = x_train.columns.tolist()  # å‡è®¾x_trainæ˜¯è®­ç»ƒæ•°æ®
# joblib.dump(feature_names, 'feature_names.pkl')

# # ä¿å­˜åˆ†ç±»å­—æ®µé€‰é¡¹ï¼ˆé€‚é…ä½ çš„ç¦»æ•£åŒ–/ç¼–ç é€»è¾‘ï¼‰
# category_options = {
#     'Contract': ['Month-to-month', 'One year', 'Two years'],
#     'PaymentMethod': ['Electronic check', 'Mailed check', 'Bank transfer', 'Credit card'],
#     'MonthlyCharges': ['1', '2', '3', '4'],  # ä½ çš„å››åˆ†ä½æ ‡ç­¾
#     'TotalCharges': ['1', '2', '3', '4']
# }
# joblib.dump(category_options, 'category_options.pkl')











# In[ ]:


# # -*- coding: utf-8 -*-
# """
# ç”µä¿¡å®¢æˆ·æµå¤±é¢„æµ‹æ¨¡å‹è®­ç»ƒè„šæœ¬
# åŠŸèƒ½ï¼šæ•°æ®é¢„å¤„ç†ã€ç‰¹å¾å·¥ç¨‹ã€æ¨¡å‹è®­ç»ƒä¸ä¿å­˜
# """

# # ===== 1. åº“å¯¼å…¥ =====
# import pandas as pd
# import numpy as np
# import matplotlib.pyplot as plt
# import seaborn as sns
# from sklearn.preprocessing import LabelEncoder
# from sklearn.model_selection import train_test_split
# from imblearn.over_sampling import SMOTE
# from xgboost import XGBClassifier
# import joblib
# import warnings
# warnings.filterwarnings("ignore")

# # å¯è§†åŒ–è®¾ç½®
# sns.set(style='darkgrid', font_scale=1.2)
# plt.rcParams['font.sans-serif'] = ['SimHei']  # ä¸­æ–‡æ˜¾ç¤º
# plt.rcParams['axes.unicode_minus'] = False    # è´Ÿå·æ˜¾ç¤º

# # ===== 2. æ•°æ®åŠ è½½ä¸æ¸…æ´— =====
# def load_and_clean_data(filepath):
#     """æ•°æ®åŠ è½½å’Œæ¸…æ´—å‡½æ•°"""
#     print("â³ æ­£åœ¨åŠ è½½æ•°æ®...")
#     telcom = pd.read_csv(filepath)
    
#     # æ•°æ®éªŒè¯
#     print("\nâœ… æ•°æ®å®Œæ•´æ€§æ£€æŸ¥:")
#     print(pd.isnull(telcom).sum())
    
#     # ç±»å‹è½¬æ¢
#     telcom['TotalCharges'] = pd.to_numeric(telcom['TotalCharges'], errors='coerce')
#     telcom.fillna({'TotalCharges': telcom['TotalCharges'].median()}, inplace=True)
    
#     # ç›®æ ‡å˜é‡ç¼–ç 
#     telcom['Churn'] = telcom['Churn'].map({'Yes': 1, 'No': 0})
    
#     print("\nğŸ“Š æµå¤±åˆ†å¸ƒ:")
#     print(telcom["Churn"].value_counts())
#     return telcom

# # ===== 3. ç‰¹å¾å·¥ç¨‹ =====
# def feature_engineering(df):
#     """ç‰¹å¾å¤„ç†å‡½æ•°"""
#     print("\nğŸ”§ æ­£åœ¨è¿›è¡Œç‰¹å¾å·¥ç¨‹...")
#     churn_var = df.iloc[:, 2:20].drop("PhoneService", axis=1)
    
#     # é‡çº²å¤„ç†ï¼ˆå››åˆ†ä½ç¦»æ•£åŒ–ï¼‰
#     for col in ['MonthlyCharges', 'TotalCharges']:
#         churn_var[col] = pd.qcut(churn_var[col], 4, labels=['1','2','3','4']).astype(int)
    
#     # åˆ†ç±»å˜é‡å¤„ç†
#     churn_var.replace({
#         'No internet service': 'No',
#         'No phone service': 'No'
#     }, inplace=True)
    
#     # æ•´æ•°ç¼–ç 
#     cat_cols = churn_var.select_dtypes(['object']).columns
#     for col in cat_cols:
#         churn_var[col] = LabelEncoder().fit_transform(churn_var[col])
    
#     return churn_var

# # ===== 4. ä¸»æ‰§è¡Œæµç¨‹ =====
# if __name__ == "__main__":
#     # æ•°æ®åŠ è½½
#     data = load_and_clean_data('Customer-Churn.csv')
    
#     # ç‰¹å¾å·¥ç¨‹
#     features = feature_engineering(data)
#     target = data['Churn']
    
#     # å¤„ç†æ ·æœ¬ä¸å‡è¡¡
#     print("\nâš–ï¸ æ­£åœ¨å¤„ç†æ ·æœ¬ä¸å‡è¡¡...")
#     X_resampled, y_resampled = SMOTE(random_state=42).fit_resample(features, target)
    
#     # æ•°æ®é›†åˆ’åˆ†
#     X_train, X_test, y_train, y_test = train_test_split(
#         X_resampled, y_resampled, 
#         test_size=0.3, 
#         random_state=42,
#         stratify=y_resampled
#     )
    
#     # æ¨¡å‹è®­ç»ƒ
#     print("\nğŸ¤– æ­£åœ¨è®­ç»ƒXGBoostæ¨¡å‹...")
#     model = XGBClassifier()
#     model.fit(X_train, y_train)
    
#     # æ¨¡å‹ä¿å­˜
#     joblib.dump(model, 'xgb_model.pkl')
#     joblib.dump(X_train.columns.tolist(), 'feature_names.pkl')
    
#     # ä¿å­˜åˆ†ç±»é€‰é¡¹ï¼ˆç”¨äºStreamlitï¼‰
#     category_options = {
#         'Contract': ['Month-to-month', 'One year', 'Two years'],
#         'PaymentMethod': ['Electronic check', 'Mailed check', 'Bank transfer', 'Credit card'],
#         'MonthlyCharges': ['1', '2', '3', '4'],
#         'TotalCharges': ['1', '2', '3', '4']
#     }
#     joblib.dump(category_options, 'category_options.pkl')
    
#     print("\nğŸ‰ æ¨¡å‹è®­ç»ƒå®Œæˆï¼å·²ä¿å­˜ä»¥ä¸‹æ–‡ä»¶ï¼š")
#     print("- xgb_model.pkl (è®­ç»ƒå¥½çš„æ¨¡å‹)")
#     print("- feature_names.pkl (ç‰¹å¾åç§°)")
#     print("- category_options.pkl (åˆ†ç±»é€‰é¡¹)")






# """
# ç”µä¿¡å®¢æˆ·æµå¤±é¢„æµ‹æ¨¡å‹è®­ç»ƒè„šæœ¬ï¼ˆä¿®æ­£ç‰ˆï¼‰
# ä¸»è¦ä¿®æ”¹ï¼š
# 1. ä½¿ç”¨ColumnTransformeræ›¿ä»£æ‰‹åŠ¨ç¼–ç 
# 2. ä¿å­˜å®Œæ•´çš„é¢„å¤„ç†ç®¡é“
# 3. ç¡®ä¿ç‰¹å¾å¤„ç†ä¸€è‡´æ€§
# """

# # ===== 1. åº“å¯¼å…¥ =====
import pandas as pd
import numpy as np
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import make_pipeline
from xgboost import XGBClassifier
import joblib

# ===== 2. æ•°æ®é¢„å¤„ç† =====
def preprocess_data(filepath):
    """æ•°æ®åŠ è½½å’ŒåŸºç¡€æ¸…æ´—"""
    df = pd.read_csv(filepath)
    
    # å¤„ç†ç¼ºå¤±å€¼å’Œç±»å‹è½¬æ¢
    df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')
    df['TotalCharges'].fillna(df['TotalCharges'].median(), inplace=True)
    
    # ç›®æ ‡å˜é‡ç¼–ç 
    df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})
    
    return df

# ===== 3. ç‰¹å¾å·¥ç¨‹ä¸æ¨¡å‹è®­ç»ƒ =====
if __name__ == "__main__":
    # æ•°æ®åŠ è½½
    data = preprocess_data('Customer-Churn.csv')
    
    # å®šä¹‰ç‰¹å¾åˆ—
    numerical_features = ['tenure', 'TotalCharges']
    categorical_features = ['Contract', 'PaymentMethod', 'InternetService']
    
    # æ„å»ºé¢„å¤„ç†ç®¡é“
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', 'passthrough', numerical_features),
            ('cat', OneHotEncoder(), categorical_features)
        ])
    
    # åˆ›å»ºå®Œæ•´ç®¡é“ï¼ˆåŒ…å«SMOTEå’Œæ¨¡å‹ï¼‰
    pipeline = make_pipeline(
        preprocessor,
        SMOTE(random_state=42),
        XGBClassifier(enable_categorical=True)  # å¯ç”¨åˆ†ç±»æ”¯æŒ
    )
    
    # å‡†å¤‡æ•°æ®
    X = data.drop('Churn', axis=1)
    y = data['Churn']
    
    # è®­ç»ƒæ¨¡å‹
    pipeline.fit(X, y)
    
    # ä¿å­˜å®Œæ•´ç®¡é“
    joblib.dump(pipeline, 'churn_pipeline.pkl')
    
    # ä¿å­˜ç‰¹å¾åç§°ï¼ˆç”¨äºStreamlitè¾“å…¥éªŒè¯ï¼‰
    feature_metadata = {
        'numerical': numerical_features,
        'categorical': {
            'Contract': ['Month-to-month', 'One year', 'Two years'],
            'PaymentMethod': ['Electronic check', 'Mailed check', 'Bank transfer', 'Credit card'],
            'InternetService': ['DSL', 'Fiber optic', 'No']
        }
    }
    joblib.dump(feature_metadata, 'feature_metadata.pkl')
    
    print("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼å·²ä¿å­˜ï¼š")
    print("- churn_pipeline.pkl (å®Œæ•´é¢„å¤„ç†+æ¨¡å‹ç®¡é“)")
    print("- feature_metadata.pkl (ç‰¹å¾å…ƒæ•°æ®)")







